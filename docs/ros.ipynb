{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROS integration\n",
    "\n",
    "rigid_body_motion supports certain ROS functionality, provided the Python environment has been set up with the required ROS packages. This guide assumes that you are at least somewhat familiar with ROS concepts such as nodes, publishers/subscribers and messages. If not, the [ROS tutorials](http://wiki.ros.org/ROS/Tutorials) are a good place to start.\n",
    "\n",
    "You also need to set up a couple of dependencies which can be done very conveniently if you are using an Anaconda Python distribution. See [the ROS dependencies installation guide](installation.rst#ros-install) for further information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note\n",
    "    \n",
    "The following examples require the `pooch`, `xarray`, `netcdf4` and `ipywidgets` libraries.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rigid_body_motion as rbm\n",
    "import rospy\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from rosbag files\n",
    "\n",
    "Data can be loaded from rosbag files into numpy arrays. So far, `geometry_msgs/TransformStamped` and `nav_msgs/Odometry` messages are supported. This is done through the `RosbagReader` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = rbm.ros.RosbagReader(rbm.example_data[\"rosbag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reader can be used as a context manager to facilitate opening and closing of the rosbag. The `get_topics_and_types` method returns a dict with topic names and corresponding message types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/pupil/left_eye/transform': 'geometry_msgs/TransformStamped',\n",
       " '/pupil/right_eye/transform': 'geometry_msgs/TransformStamped',\n",
       " '/t265/transform': 'geometry_msgs/TransformStamped'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with reader:\n",
    "    info = reader.get_topics_and_types()\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data included in the example rosbag is from a [head/eye tracking study](https://dl.acm.org/doi/pdf/10.1145/3379156.3391365) and contains head-in-world pose estimated by the Intel RealSense T265 as well as eye-in-head pose for both eyes estimated by the Pupil Core eye tracker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_messages` method returns a dict with the data from a specified topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamps': array([1.58060323e+09, 1.58060323e+09, 1.58060323e+09, ...,\n",
       "        1.58060357e+09, 1.58060357e+09, 1.58060357e+09]),\n",
       " 'position': array([[15.9316,  0.8211, 10.5429],\n",
       "        [15.9354,  0.8208, 10.5382],\n",
       "        [15.9393,  0.8204, 10.5335],\n",
       "        ...,\n",
       "        [29.8883,  2.8952,  7.6317],\n",
       "        [29.8888,  2.8943,  7.6249],\n",
       "        [29.8892,  2.8935,  7.6182]]),\n",
       " 'orientation': array([[-0.9687,  0.0917,  0.2306,  0.0039],\n",
       "        [-0.969 ,  0.0915,  0.2295,  0.005 ],\n",
       "        [-0.9693,  0.0912,  0.2285,  0.0061],\n",
       "        ...,\n",
       "        [-0.9915,  0.0915,  0.0929, -0.0022],\n",
       "        [-0.9914,  0.0922,  0.0927, -0.0017],\n",
       "        [-0.9913,  0.0932,  0.0925, -0.001 ]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with reader:\n",
    "    head = reader.load_messages(\"/t265/transform\")\n",
    "head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can construct a reference frame tree with this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.register_frame(\"world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_T265_ROS = np.array([[0.0, 0.0, -1.0], [-1.0, 0.0, 0.0], [0.0, 1.0, 0.0]])\n",
    "\n",
    "rbm.ReferenceFrame.from_rotation_matrix(\n",
    "    R_T265_ROS, parent=\"world\", name=\"t265/world\"\n",
    ").register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.register_frame(\n",
    "    \"t265/tracker\",\n",
    "    parent=\"t265/world\",\n",
    "    translation=head[\"position\"],\n",
    "    rotation=head[\"orientation\"],\n",
    "    timestamps=head[\"timestamps\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.ReferenceFrame.from_rotation_matrix(\n",
    "    R_T265_ROS, parent=\"t265/tracker\", name=\"head\", inverse=True,\n",
    ").register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n",
      "└── t265/world\n",
      "    └── t265/tracker\n",
      "        └── head\n"
     ]
    }
   ],
   "source": [
    "rbm.render_tree(\"world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization with RViz\n",
    "\n",
    "You can download an `.rviz` file where all topics created in the following are already set up [here](_static/example.rviz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node(\"rbm_vis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_world_head = rbm.ros.ReferenceFrameTransformBroadcaster(\"head\", base=\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_world_head.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_publisher = rbm.ros.ReferenceFrameMarkerPublisher(\"head\", base=\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_publisher.publish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"_static/img/rviz_1.png\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with reader:\n",
    "    left_eye = reader.load_dataset(\"/pupil/left_eye/transform\", cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_t265_pupil = (24.5e-3, -29e-3, 0.0)\n",
    "r_t265_pupil = (-0.00125, -1.0, 6.3463e-05, 3.977e-06)\n",
    "\n",
    "rbm.register_frame(\n",
    "    \"pupil/scene_cam\",\n",
    "    parent=\"t265/tracker\",\n",
    "    translation=t_t265_pupil,\n",
    "    rotation=r_t265_pupil,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.ReferenceFrame.from_dataset(\n",
    "    left_eye,\n",
    "    \"position\",\n",
    "    \"orientation\",\n",
    "    \"time\",\n",
    "    parent=\"pupil/scene_cam\",\n",
    "    name=\"pupil/left_eye\",\n",
    ").register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_PUPIL_ROS = np.array([[0.0, -1.0, 0.0], [0.0, 0.0, -1.0], [1.0, 0.0, 0.0]])\n",
    "\n",
    "rbm.ReferenceFrame.from_rotation_matrix(\n",
    "    R_PUPIL_ROS, parent=\"pupil/left_eye\", name=\"left_eye\"\n",
    ").register(update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n",
      "└── t265/world\n",
      "    └── t265/tracker\n",
      "        ├── head\n",
      "        └── pupil/scene_cam\n",
      "            └── pupil/left_eye\n",
      "                └── left_eye\n"
     ]
    }
   ],
   "source": [
    "rbm.render_tree(\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_head_left_eye = rbm.ros.ReferenceFrameTransformBroadcaster(\n",
    "    \"left_eye\", base=\"head\", publish_pose=True, subscribe=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_head_left_eye.spin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e07ceb14bdc425c82519421f13381f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, description='Index', max=66628), Button(description='◄◄', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81ae29de6c14f74980d615c1dfd9e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rbm.ros.play_publisher(tf_world_head, step=2, skip=1, speed=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"_static/img/rviz_2.png\" style=\"width: 800px;\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rbm]",
   "language": "python",
   "name": "conda-env-rbm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
